{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install deep_translator"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bk5rGvXdbuPG",
        "outputId": "7f983262-9c2c-48ff-9db6-b4e265337e50"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting deep_translator\n",
            "  Downloading deep_translator-1.11.4-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.9.1 in /usr/local/lib/python3.11/dist-packages (from deep_translator) (4.13.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from deep_translator) (2.32.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep_translator) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep_translator) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.23.0->deep_translator) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.23.0->deep_translator) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.23.0->deep_translator) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.23.0->deep_translator) (2025.1.31)\n",
            "Downloading deep_translator-1.11.4-py3-none-any.whl (42 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: deep_translator\n",
            "Successfully installed deep_translator-1.11.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import pandas as pd\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "import os\n",
        "from datetime import date,datetime\n",
        "import csv\n",
        "from deep_translator import GoogleTranslator"
      ],
      "metadata": {
        "id": "Qjs8cbzDWJ6V"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Clases de la IA\n",
        "CLASS_NAMES = {\n",
        "        0: 'apple_pie', 1: 'baby_back_ribs', 2: 'baklava', 3: 'beef_carpaccio',\n",
        "        4: 'beef_tartare', 5: 'beet_salad', 6: 'beignets', 7: 'bibimbap',\n",
        "        8: 'bread_pudding', 9: 'breakfast_burrito', 10: 'bruschetta', 11: 'caesar_salad',\n",
        "        12: 'cannoli', 13: 'caprese_salad', 14: 'carrot_cake', 15: 'ceviche',\n",
        "        16: 'cheese_plate', 17: 'cheesecake', 18: 'chicken_curry', 19: 'chicken_quesadilla',\n",
        "        20: 'chicken_wings', 21: 'chocolate_cake', 22: 'chocolate_mousse', 23: 'churros',\n",
        "        24: 'clam_chowder', 25: 'club_sandwich', 26: 'crab_cakes', 27: 'creme_brulee',\n",
        "        28: 'croque_madame', 29: 'cup_cakes', 30: 'deviled_eggs', 31: 'donuts',\n",
        "        32: 'dumplings', 33: 'edamame', 34: 'eggs_benedict', 35: 'escargots',\n",
        "        36: 'falafel', 37: 'filet_mignon', 38: 'fish_and_chips', 39: 'foie_gras',\n",
        "        40: 'french_fries', 41: 'french_onion_soup', 42: 'french_toast', 43: 'fried_calamari',\n",
        "        44: 'fried_rice', 45: 'frozen_yogurt', 46: 'garlic_bread', 47: 'gnocchi',\n",
        "        48: 'greek_salad', 49: 'grilled_cheese_sandwich', 50: 'grilled_salmon',\n",
        "        51: 'guacamole', 52: 'gyoza', 53: 'hamburger', 54: 'hot_and_sour_soup',\n",
        "        55: 'hot_dog', 56: 'huevos_rancheros', 57: 'hummus', 58: 'ice_cream',\n",
        "        59: 'lasagna', 60: 'lobster_bisque', 61: 'lobster_roll_sandwich',\n",
        "        62: 'macaroni_and_cheese', 63: 'macarons', 64: 'miso_soup', 65: 'mussels',\n",
        "        66: 'nachos', 67: 'omelette', 68: 'onion_rings', 69: 'oysters', 70: 'pad_thai',\n",
        "        71: 'paella', 72: 'pancakes', 73: 'panna_cotta', 74: 'peking_duck', 75: 'pho',\n",
        "        76: 'pizza', 77: 'pork_chop', 78: 'poutine', 79: 'prime_rib',\n",
        "        80: 'pulled_pork_sandwich', 81: 'ramen', 82: 'ravioli', 83: 'red_velvet_cake',\n",
        "        84: 'risotto', 85: 'samosa', 86: 'sashimi', 87: 'scallops', 88: 'seaweed_salad',\n",
        "        89: 'shrimp_and_grits', 90: 'spaghetti_bolognese', 91: 'spaghetti_carbonara',\n",
        "        92: 'spring_rolls', 93: 'steak', 94: 'strawberry_shortcake', 95: 'sushi',\n",
        "        96: 'tacos', 97: 'takoyaki', 98: 'tiramisu', 99: 'tuna_tartare', 100: 'waffles'\n",
        "    }"
      ],
      "metadata": {
        "id": "bDKuR2-2W34Z"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjoO9zKHV8sj",
        "outputId": "13d5ebf0-8da2-40b3-fdff-0c8ac1e7d2df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/optimizers/base_optimizer.py:86: UserWarning: Argument `decay` is no longer supported and will be ignored.\n",
            "  warnings.warn(\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "modelo cargado exitosamente\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step\n",
            "[(0.66029775, 45), (0.1311844, 15), (0.042175893, 58), (0.031294852, 23), (0.022774851, 60), (0.020637188, 27), (0.012466932, 92), (0.011593915, 86), (0.010667, 73), (0.008502034, 100), (0.0072309435, 32), (0.006139246, 95), (0.005060622, 29), (0.004749234, 83), (0.0032001643, 22), (0.0028891203, 36), (0.0020967624, 85), (0.001510744, 21), (0.0014023386, 99), (0.0012919109, 82), (0.00126205, 14), (0.0010506067, 65), (0.0009226243, 0), (0.000917774, 94), (0.0008427945, 13), (0.00077905844, 62), (0.00069949124, 35), (0.00063273247, 63), (0.0005190524, 4), (0.00050489773, 69), (0.0004909811, 12), (0.00044668626, 31), (0.0004202869, 98), (0.00027972806, 30), (0.00023373314, 68), (0.00020612913, 59), (0.00020136993, 55), (0.00019999882, 66), (0.00019969654, 9), (0.00019557799, 43), (0.00016015218, 16), (0.0001367682, 2), (0.00012737868, 54), (0.00011427128, 93), (9.570714e-05, 11), (9.460384e-05, 51), (9.195625e-05, 10), (8.2728e-05, 39), (7.583863e-05, 8), (7.187067e-05, 5), (6.9840775e-05, 24), (6.3957734e-05, 37), (6.128599e-05, 49), (5.3570027e-05, 52), (5.206614e-05, 84), (4.23428e-05, 3), (3.808274e-05, 57), (3.70592e-05, 46), (3.1351832e-05, 26), (3.1324515e-05, 53), (3.0818177e-05, 89), (2.69178e-05, 17), (2.6449678e-05, 18), (2.3043653e-05, 6), (1.9669196e-05, 7), (1.8383535e-05, 41), (1.7333157e-05, 67), (1.4194075e-05, 40), (1.3512189e-05, 87), (1.21739495e-05, 71), (1.2155619e-05, 75), (1.2121515e-05, 80), (7.4130135e-06, 34), (6.931257e-06, 56), (6.543446e-06, 74), (5.483138e-06, 47), (5.040072e-06, 20), (4.518512e-06, 88), (4.367555e-06, 48), (3.7945542e-06, 76), (3.6961483e-06, 96), (2.5757101e-06, 81), (2.522016e-06, 19), (2.4189126e-06, 72), (2.3767552e-06, 79), (2.0230366e-06, 97), (1.8525694e-06, 44), (1.4464362e-06, 64), (1.3645174e-06, 90), (1.2790051e-06, 28), (8.1823083e-07, 61), (8.1103366e-07, 77), (7.029308e-07, 33), (5.4890677e-07, 50), (5.0386177e-07, 78), (4.136102e-07, 25), (3.065961e-07, 1), (6.5517064e-08, 42), (4.0146915e-08, 91), (3.8051606e-08, 70), (2.8187301e-08, 38)]\n",
            "se leyeron ambos archivos correctamente\n",
            "procesado del excel y la tabla nutricion exitosamente\n",
            "   index          label  weight  calories  protein  carbohydrates  fats  \\\n",
            "0    225  frozen_yogurt     100       150        4             25     3   \n",
            "\n",
            "   fiber  sugars  sodium  \n",
            "0      0      20      50  \n",
            "yogurt congelado tiene alto porcentaje de azucar, evitar su consumo excesivo\n"
          ]
        }
      ],
      "source": [
        "def modelo(nombre):\n",
        "  IA = tf.keras.models.load_model(nombre)\n",
        "  print(\"modelo cargado exitosamente\")\n",
        "  return IA\n",
        "\n",
        "def prediccion(IA, imagen):\n",
        "  img = imagen\n",
        "  img_redimension = image.load_img(img, target_size=(150, 150))\n",
        "  img_array = image.img_to_array(img_redimension)/255\n",
        "  img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "  prediccion = IA.predict(img_array)\n",
        "\n",
        "  predict = zip(prediccion[0],list(range(0,101)))\n",
        "  predict = list(predict)\n",
        "  ordenados = sorted(predict, key=lambda predict : predict[0],reverse=True)\n",
        "  print(ordenados)\n",
        "  prediccion_numerica = np.argmax(prediccion, axis=1)[0]\n",
        "\n",
        "  comida = CLASS_NAMES[prediccion_numerica]\n",
        "\n",
        "  return comida\n",
        "\n",
        "\n",
        "def lectura(): #tener los archivos en la misma ruta donde se ejecuta el codigo\n",
        "  data_nutricion = pd.read_csv('nutrition2.csv')\n",
        "  data_excel = pd.read_excel('tabla.xlsx')\n",
        "\n",
        "\n",
        "  print(\"se leyeron ambos archivos correctamente\")\n",
        "\n",
        "  #procesado a data excel y a data nutricion\n",
        "\n",
        "  data_nutri = data_nutricion[data_nutricion[\"weight\"] == 100]\n",
        "\n",
        "\n",
        "  filas = data_excel.iloc[1, :]\n",
        "  data_excel.columns = filas\n",
        "  data_excel.reset_index(inplace=True)\n",
        "  data_excel.drop([0,1,2], inplace=True)\n",
        "  data_excel.reset_index(inplace=True)\n",
        "  data_excel.rename(columns={\"Proteína (g)\":\"Proteina\", \"Calorías\": \"Calorias\"}, inplace=True)\n",
        "\n",
        "\n",
        "  data_excel.drop([\"index\", \"level_0\", \"Codigo\", \"Humed. (g)\", \"Fósforo (mg)\", \"Potasio (mg)\", \"Grasas (g)\", np.nan], inplace=True, axis=1)\n",
        "\n",
        "  print(\"procesado del excel y la tabla nutricion exitosamente\")\n",
        "\n",
        "  return data_nutri, data_excel\n",
        "\n",
        "def busqueda(predicion, data_nutri):\n",
        "  informacion = data_nutri[data_nutri[\"label\"] == predicion]\n",
        "  informacion.reset_index(inplace=True)\n",
        "\n",
        "  return informacion\n",
        "\n",
        "def guardado(fecha_actual,informacion):\n",
        "\n",
        "    #directorio_base=os.getcwd()+'\\\\registro_de_alimentacion.csv' USAR SOLO SI NO SE ESTA EJECUTANDO EN LA MISMA RUTA\n",
        "    nombre_registro = \"registro_de_alimentacion.csv\"\n",
        "    formato=datetime.strftime(fecha_actual,'%d/%m/%Y')\n",
        "\n",
        "    informacion.insert(0,'Fechas',[formato])\n",
        "\n",
        "    if not os.path.exists(nombre_registro):\n",
        "\n",
        "        with open('registro_de_alimentacion.csv', mode='a' ,newline='') as registro:\n",
        "            archivo=csv.writer(registro)\n",
        "            archivo.writerow(list(informacion))\n",
        "            archivo.writerow(list(informacion.loc[0,list(informacion.columns)]))\n",
        "    else:\n",
        "\n",
        "        with open('registro_de_alimentacion.csv', mode='a' ,newline='') as registro:\n",
        "            archivo=csv.writer(registro)\n",
        "            archivo.writerow(list(informacion.loc[0,list(informacion.columns)]))\n",
        "\n",
        "def traduccion(prediccion):\n",
        "  traduccion = GoogleTranslator(source='auto', target='es').translate(prediccion.replace(\"_\", \" \"))\n",
        "  return traduccion\n",
        "\n",
        "def sugerencias(informacion, data_excel):\n",
        "    nombre = informacion[\"label\"][0]\n",
        "    nombre_traducido = traduccion(nombre)\n",
        "    df = data_excel\n",
        "\n",
        "    if informacion[\"sugars\"][0] > 15:\n",
        "\n",
        "        print(f\"{nombre_traducido} tiene alto porcentaje de azucar, evitar su consumo excesivo\")\n",
        "    else:\n",
        "\n",
        "        if informacion[\"calories\"][0] <= 400 and informacion[\"protein\"][0] >= 20:\n",
        "\n",
        "            if informacion[\"carbohydrates\"][0] > 45:\n",
        "              print(f\"{nombre_traducido} tiene buen porcentaje en proteinas y carbohidratos pero es bajo en calorias, aqui unas sugerencias con que complementarlo: \")\n",
        "              recomendaciones = df[(df['Calorias'] > 300) & (df['Proteina'] < 20)]\n",
        "\n",
        "            else:\n",
        "              print(f\"{nombre_traducido} tiene buen porcentaje en proteinas pero es bajo en calorias y carbohidratos, aqui unas sugerencias con que complementarlo: \")\n",
        "              recomendaciones = df[(df['Calorias'] > 300) & (df['Carbohidratos'] > 25)]\n",
        "\n",
        "        elif informacion[\"calories\"][0] > 100 and informacion[\"protein\"][0] < 20:\n",
        "\n",
        "            if informacion[\"carbohydrates\"][0] > 45:\n",
        "                print(f\"{nombre_traducido} tiene un buen porcentaje de calorias y carbohidratos pero es bajo en proteinas, aqui unas sugerencias con que complementarlo: \")\n",
        "                recomendaciones = df[(df['Proteina'] > 20) & (df['Calorias'] < 100)]\n",
        "            else:\n",
        "                print(f\"{nombre_traducido} tiene un buen porcentaje de calorias pero es bajo en proteinas y carbohidratos, aqui unas sugerencias con que complementarlo: \")\n",
        "                recomendaciones = df[(df['Proteina'] > 20) & (df['Carbohidratos'] > 25)]\n",
        "\n",
        "        elif informacion[\"calories\"][0] < 300 and informacion[\"protein\"][0] < 20:\n",
        "\n",
        "            if informacion[\"carbohydrates\"][0] > 45:\n",
        "                print(f\"{nombre_traducido} tiene buen porcentaje de carbohidratos pero es bajo en calorias y en proteinas, te recomendamos aumentar ambas con unos alimentos sugeridos: \")\n",
        "                recomendaciones = df[(df['Calorias'] > 300) & (df['Proteina'] > 20)]\n",
        "            else:\n",
        "                print(f\"{nombre_traducido} es bajo en calorias, en proteinas y en carbohidratos, te recomendamos aumentar ambas con unos alimentos sugeridos: \")\n",
        "                recomendaciones = df[(df['Calorias'] > 300) & (df['Proteina'] > 20) & (df['Carbohidratos'] > 25)]\n",
        "        else:\n",
        "\n",
        "            print(f\"{nombre_traducido} es alto en calorias y en proteinas pero bajo en carbohidratos, aqui unas sugerencias para complementarlo: \")\n",
        "            recomendaciones = df[(df['Carbohidratos'] > 25) & (df['Calorias'] < 300) & (df['Proteina'] < 20)]\n",
        "\n",
        "\n",
        "        if not recomendaciones.empty:\n",
        "          recomendaciones = recomendaciones.sample(n=min(3, len(recomendaciones)))\n",
        "          #print(recomendaciones)\n",
        "          print(\"Te recomendamos las siguientes comidas:\")\n",
        "          for _, row in recomendaciones.iterrows():\n",
        "              nombre_recomendado = row['Alimento']\n",
        "              print(f\"- {nombre_recomendado} (Calorías: {row['Calorias']}, Proteínas: {row['Proteina']}, Carbohidratos: {row['Carbohidratos']})\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "IA = modelo(\"apa.h5\")\n",
        "\n",
        "ruta = \"77987.jpg\" #colocar aqui el nombre de la imagen o la ruta\n",
        "\n",
        "prediccion = prediccion(IA, ruta)\n",
        "\n",
        "data_nutri, data_excel = lectura() #dataframes\n",
        "\n",
        "informacion = busqueda(prediccion, data_nutri) #data frame alimento\n",
        "\n",
        "sugerencias(informacion, data_excel) #recomendaciones\n",
        "\n",
        "guardado(date.today(), informacion)\n",
        "\n"
      ]
    }
  ]
}